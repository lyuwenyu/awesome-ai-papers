# Awesome AI Papers


## Github resource
Name | Info
---|---
[Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models) | llm, mm-llm


## Computer Vision

name| Info
---|---
[Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks](https://arxiv.org/abs/2311.06242) | cv, foundation model

## Multimodal Large Language Model
name| Info
---|---
[4M: Massively Multimodal Masked Modeling](https://arxiv.org/abs/2312.06647) | vision fundation model, apple
[OneLLM: One Framework to Align All Modalities with Language](https://arxiv.org/pdf/2312.03700.pdf) |  mllm, mmlab
[Pixel Aligned Language Models](https://jerryxu.net/PixelLLM/) |  pixel-llm, google
[Generative Multimodal Models are In-Context Learners](https://baaivision.github.io/emu2/) |  emu2, baai
[Data-Efficient Instruction Tuning for Alignment](https://arxiv.org/pdf/2312.15685.pdf) | Deita, sft


